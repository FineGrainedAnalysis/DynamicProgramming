#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t c:nil creator:comment d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t toc:t todo:t |:t
#+TITLE: Fine Grained Analysis of Dynamic Programming
#+DATE: <2018-05-08 Tue>
#+AUTHOR: Jérémy Barbay
#+EMAIL: jeremy@barbay.cl
#+DESCRIPTION: Notes about the Fine Grained Analysis of Dynamic Programming for various problems.
#+KEYWORDS: Adaptive, Dynamic Programming, Fine Grained Analysis
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.4.1 (Org mode 8.2.5h)

* Introduction
** Recursivity
According to [[https://en.wikipedia.org/wiki/Recursion][Wikipedia/Recursion]]

#+BEGIN_QUOTE
Recursion occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no loop or infinite chain of references can occur.
#+END_QUOTE

** Dynamic Programming

According to [[https://en.wikipedia.org/wiki/Dynamic_programming][Wikipedia/DynamicProgramming]]:
#+BEGIN_QUOTE
In computer science, mathematics, management science, economics and bioinformatics, dynamic programming (also known as dynamic optimization) is a method for solving a complex problem by breaking it down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, one simply looks up the previously computed solution, thereby saving computation time at the expense of (it is hoped) a modest expenditure in storage space. (Each of the subproblem solutions is indexed in some way, typically based on the values of its input parameters, so as to facilitate its lookup.) The technique of storing solutions to subproblems instead of recomputing them is called "memoization".
#+END_QUOTE

** Fine Grained Analysis
* Problems with a Fine Grained Analysis
** Insert Swap Edit Distance
** Orthogonal Vectors
** discrete Frechet Distance
** Frechet Distance
** Longuest Common Sub Sequence and Delete Insert Edit Distance
** Delete Insert Replace Edit Distance
** Delete Replace Edit Distance and Insert Replace Edit Distance
* Problems without a Fine Grained Analysis so far
** Coin Change Problem  [[[https://en.wikipedia.org/wiki/Dynamic_programming][Wikipedia]]]
** Optimal consumption and saving  [[[https://en.wikipedia.org/wiki/Dynamic_programming][Wikipedia]]]
** Sequence alignment   [[[https://en.wikipedia.org/wiki/Dynamic_programming][Wikipedia]]]
** Matrix chain multiplication
* Algorithms that use dynamic programming
Once again, according to [[https://en.wikipedia.org/wiki/Dynamic_programming][Wikipedia]]:

    1. [ ] Recurrent solutions to lattice models for protein-DNA binding
    2. [ ] Backward induction as a solution method for finite-horizon discrete-time dynamic optimization problems
    3. [ ] Method of undetermined coefficients can be used to solve the Bellman equation in infinite-horizon, discrete-time, discounted, time-invariant dynamic optimization problems
    4. [ ] Many string algorithms including longest common subsequence, longest increasing subsequence, longest common substring, Levenshtein distance (edit distance)
    5. [ ] Many algorithmic problems on graphs can be solved efficiently for graphs of bounded treewidth or bounded clique-width by using dynamic programming on a tree decomposition of the graph.
    6. [ ] The Cocke–Younger–Kasami (CYK) algorithm which determines whether and how a given string can be generated by a given context-free grammar
    7. [ ] Knuth's word wrapping algorithm that minimizes raggedness when word wrapping text
    8. [ ] The use of transposition tables and refutation tables in computer chess
    9. [ ] The Viterbi algorithm (used for hidden Markov models)
    10. [ ] The Earley algorithm (a type of chart parser)
    11. [ ] The Needleman–Wunsch algorithm and other algorithms used in bioinformatics, including sequence alignment, structural alignment, RNA structure prediction
    12. [ ] Floyd's all-pairs shortest path algorithm
    13. [ ] Optimizing the order for chain matrix multiplication
    14. [ ] Pseudo-polynomial time algorithms for the subset sum, knapsack and partition problems
    15. [ ] The dynamic time warping algorithm for computing the global distance between two time series
    16. [ ] The Selinger (a.k.a. System R) algorithm for relational database query optimization
    17. [ ] De Boor algorithm for evaluating B-spline curves
    18. [ ] Duckworth–Lewis method for resolving the problem when games of cricket are interrupted
    19. [ ] The value iteration method for solving Markov decision processes
    20. [ ] Some graphic image edge following selection methods such as the "magnet" selection tool in Photoshop
    21. [ ] Some methods for solving interval scheduling problems
    22. [ ] Some methods for solving the travelling salesman problem, either exactly (in exponential time) or approximately (e.g. via the bitonic tour)
    23. [ ] Recursive least squares method
    24. [ ] Beat tracking in music information retrieval
    25. [ ] Adaptive-critic training strategy for artificial neural networks
    26. [ ] Stereo algorithms for solving the correspondence problem used in stereo vision
    27. [ ] Seam carving (content-aware image resizing)
    28. [ ] The Bellman–Ford algorithm for finding the shortest distance in a graph
    29. [ ] Some approximate solution methods for the linear search problem
    30. [ ] Kadane's algorithm for the maximum subarray problem


* Discussion
